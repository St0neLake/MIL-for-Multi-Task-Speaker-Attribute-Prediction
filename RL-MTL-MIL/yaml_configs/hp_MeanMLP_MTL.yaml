method: bayes
metric:
  goal: maximize # Or minimize if using a combined loss
  name: eval/avg_F1 # CHANGED: Example: Average F1 across tasks. Ensure run_mil.py logs this.
                   # If run_mil.py logs individual F1s (e.g. eval/age_f1, eval/gender_f1),
                   # you might need a custom script to calculate and log eval/avg_F1,
                   # or W&B might allow defining a metric based on others.
                   # Alternatively, stick to minimizing a combined 'eval/loss'.
parameters:
  # --- Hyperparameters to sweep using distributions ---

  learning_rate:
    distribution: log_uniform_values
    min: 1.0e-05
    max: 1.0e-03

  hidden_dim: # Hidden dimension for the task-specific heads
    distribution: categorical
    values: [64, 128, 256]

  # --- Hyperparameters kept constant for this sweep ---
  # You can move any of these to the section above to sweep them as well.

  epochs:
    distribution: constant
    value: 800 # A fixed number of epochs is often fine if using early stopping

  batch_size:
    distribution: constant
    value: 64

  dropout_p:
    distribution: constant
    value: 0.5

  scheduler_patience:
    distribution: constant
    value: 5

  early_stopping_patience:
    distribution: constant
    value: 20 # A reasonable patience for MIL pre-tuning

run_cap: 50 # Number of sweep runs